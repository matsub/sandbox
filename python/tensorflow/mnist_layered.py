# -*- coding: utf-8 -*-
"""MNIST_layered.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ebhOkE33zcmIIL9GjICyDHP0dKEZ66Sd
"""

import tensorflow as tf
sess = tf.InteractiveSession()

from tensorflow.python.client import device_lib
device_lib.list_local_devices()

from tensorflow.examples.tutorials.mnist import input_data
mnist = input_data.read_data_sets('MNIST_data', one_hot=True)

x = tf.placeholder(tf.float32, shape=[None, 784])
y = tf.placeholder(tf.float32, shape=[None, 10])

input_layer = tf.reshape(x, [-1, 28, 28, 1])

# Convolutional Layer #1 and Pooling Layer #1
conv1 = tf.layers.conv2d(
      inputs=input_layer,
      filters=32,
      kernel_size=[5, 5],
      padding="same",
      activation=tf.nn.relu)
pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)

# Convolutional Layer #2 and Pooling Layer #2
conv2 = tf.layers.conv2d(
      inputs=pool1,
      filters=64,
      kernel_size=[5, 5],
      padding="same",
      activation=tf.nn.relu)
pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)

# Dense Layer
pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])
dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)

training = tf.placeholder(tf.bool, shape=())
dropout = tf.layers.dropout(inputs=dense, rate=0.5, training=training)

# Logits Layer
logits = tf.layers.dense(inputs=dropout, units=10)

# Calculate Loss
cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=logits)

# Configure the Training Op
optimizer = tf.train.AdamOptimizer(1e-4)
train_op = optimizer.minimize(cross_entropy)

# Calculate accuracy
correct_prediction = tf.equal(tf.argmax(logits,1), tf.argmax(y,1))
accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))

# run
sess.run(tf.global_variables_initializer())
for i in range(1000):
  batch = mnist.train.next_batch(50)
  if i%100 == 0:
    train_accuracy = accuracy.eval(feed_dict={
        x:batch[0], y: batch[1], training: False})
    print("step %d, training accuracy %g" % (i, train_accuracy))
  train_op.run(feed_dict={x: batch[0], y: batch[1], training: True})

print("test accuracy %g" % accuracy.eval(feed_dict={
    x: mnist.test.images, y: mnist.test.labels, training: False}))